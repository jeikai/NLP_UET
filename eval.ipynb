{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:58:20.086351700Z",
     "start_time": "2023-12-12T07:58:15.805349700Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m features \u001B[38;5;241m=\u001B[39m [l\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m feature\u001B[38;5;241m.\u001B[39mreadlines()]\n\u001B[0;32m      5\u001B[0m translates \u001B[38;5;241m=\u001B[39m [l\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m translate\u001B[38;5;241m.\u001B[39mreadlines()]\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mbleu_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtranslates\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Ki_1_Nam_3\\NLP\\KC4.0_MultilingualNMT\\venv\\lib\\site-packages\\torchtext\\data\\metrics.py:72\u001B[0m, in \u001B[0;36mbleu_score\u001B[1;34m(candidate_corpus, references_corpus, max_n, weights)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# Get the length of the reference that's closest in length to the candidate\u001B[39;00m\n\u001B[0;32m     71\u001B[0m refs_len_list \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mlen\u001B[39m(ref)) \u001B[38;5;28;01mfor\u001B[39;00m ref \u001B[38;5;129;01min\u001B[39;00m refs]\n\u001B[1;32m---> 72\u001B[0m refs_len \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrefs_len_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mabs\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m reference_counters \u001B[38;5;241m=\u001B[39m _compute_ngram_counter(refs[\u001B[38;5;241m0\u001B[39m], max_n)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ref \u001B[38;5;129;01min\u001B[39;00m refs[\u001B[38;5;241m1\u001B[39m:]:\n",
      "\u001B[1;31mValueError\u001B[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "from torchtext.data import bleu_score\n",
    "\n",
    "with open(\"data/feature.lo\", mode=\"r\", encoding=\"utf-8\") as feature, open(\"data/translate.lo2vi.vi\", mode=\"r\", encoding=\"utf-8\") as translate:\n",
    "    features = [l.split() for l in feature.readlines()]\n",
    "    translates = [l.split() for l in translate.readlines()]\n",
    "    \n",
    "    print(bleu_score(features,translates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.00, 4.7/0.1/0.0/0.0 (BP=1.000, ratio=1.427, hyp_len=2661, ref_len=1865)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLC_ALL = \"en_US.UTF-8\",\n",
      "\t(possibly more locale environment variables)\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the system default locale (\"English_United States.1252\").\n",
      "Use of uninitialized value in division (/) at third-party/multi-bleu.perl line 139, <STDIN> line 97.\n",
      "Use of uninitialized value in division (/) at third-party/multi-bleu.perl line 139, <STDIN> line 97.\n",
      "It is in-advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl third-party/multi-bleu.perl data/translate.lo2vi.vi < data/expected.vi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T08:34:55.048678700Z",
     "start_time": "2023-12-12T08:34:54.843678600Z"
    }
   },
   "id": "ea4daa64fb67f78f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 2.81, 13.0/3.1/1.6/0.9 (BP=1.000, ratio=1.344, hyp_len=36861, ref_len=27418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLC_ALL = \"en_US.UTF-8\",\n",
      "\t(possibly more locale environment variables)\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the system default locale (\"English_United States.1252\").\n",
      "It is in-advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl third-party/multi-bleu.perl data/translate.lo2vi2.vi < data/Dev/tst2023.vi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T08:34:56.370679800Z",
     "start_time": "2023-12-12T08:34:56.148680Z"
    }
   },
   "id": "7a894e1fbfee8a3b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
